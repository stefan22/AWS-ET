## Implementing Elasticity
		
###		Bootstrapping

		- Bootstrapping refers to creating a self-sustaining startup process that can run on its own
		- In the context of AWS, it means the process needed to get your app running on an EC2 instance
		- Tell instances who they are and what role -ie: app server, db server
		- These instances should be able to grab needed resources -ie code files, configuration, utility scripts
		- all of it, based on the role they're playing then register itself as a component in the system

###		Sample Bootstrap Process

		- Mount needed drives
		- start needed services
		- update code files or pull down needed scripts
		- update software or apply needed patches
		- register itself with load balancer
		- start receiving traffic

### 	Bootstrapping tools

		- run custom scripts and tools
		- Chef/ Puppet
		- Opswork (free application management service avail in AWS) - built on top of the chef framework
		- Access to instance metadata
		- Cloud-Init (Linux)       //also avail through AWS
		- EC2Config (for Windows servers)      //also avail through AWS


###     Auto-Scaling groups

		- A service focus on helping you implement elasticity (not too much and too much capacity) where
		  the solution is to take advantage of the elastic nature of the cloud, and to increase capacity
		  when load demands, and to decrease capacity when load lightens
		- Auto-scaling makes this easy. You define the conditions on which you want to scale out, or in,
		  your EC2 instances. And the auto-scaling service will add, remove, instances when these conditions
		  are met.
			 
			 - lets say if average CPU utilization rises above 75% say for more than a minute, add two more
			   instances so without you doing anything you have scale system out to accomodate increased
			   demand.

		- Auto-Scaling 3 main components:

			 - launch configuration: what to scale (what EC2 instance size to use, what AMI to use, security
			   group, storage needs etc)

			 - auto-scaling group: where to launch, and define limits on the number of instances to launch
			   ie: desire capacity number

			 - scaling-policy (optional): how to launch, here u define cloudwatch alarms based on certain metrics
			   breaching specified thresholds.

###     Storage Options

		- Block Storage
			EBS / Instance Storage

		- Object Storage
			S3, Glacier, CloudFront
		
		- Storage Gateway (Sync Volumes)
			connect local environment with AWS infrastructure

		- Relational Databases
			RDS

		- NoSQL Databases
			DynamoDB

		- In-memory cache
			Elasticache


		***
		
#### S3	

		- S3 is an object Store. In an object store, objects are stored in a flat organization, which are referred
		  to as `buckets` in S3 and retrieved by a unique identifier called `keys` in S3.
		- minimal metadata management allows for almost endless scalability and very fast object retrieval
		- no search (can't search across all objects in storage)
		- built to be durable - by storing your objects on multiple devices across multiple availability zones in
		  an Amazon S3 region
		- RRS or reduced redundancy storage - is an option available in S3 which reduces your storage costs.
		- There's no defined limit to the amount of content you can store, there's however a 5TB lime on the size
		  of the object.
		- You can access object iva REST or SOAP API protocols
		- S3 works on an eventual consistency model (while your objects stored are highly available, the data
		  consistency is achieved only eventually)

		  		- achieved by replicating across devices and across zones
		  		- whenever you update an object you have to wait until the change is propragated to all the replicas
		  		  before requests will return the latest version

		  		  ie: when you delete an object, it may take some time to propagate to all replicas, so there's a
		  		      period of time where objects could still be returned after deleted and it can make it unsuitable
		  		      for data that changes frequently.


#### Glacier

		- something you can use to `freeze` your data.
		- is like an extension of S3, but suitable for archiving your data - used very infrequently
		- 3 -5 hour retrieval time
		- same durability like S3 but storage cost is much less
		- you pay per archive and per restore request -also very low cost
		- manage objects through S3
		- you can transition S3 objects to Glacier when data is ready for archiving


#### CloudFront

		- Uses a globally distributed network of edge locations to minimize latency in delivering your content
		  to the end user
		- You need to define and configure one or more origin servers

				- An origin server is the location of the definitive version of an object. Could be other
				  Amazon web services, such as Amazon S3 bucket, an Amazon EC2, or an elastic load balancer
				  or your own origin server.

		- Then you create a distribution to register your origin server with Amazon Cloud front - through AWS
		  Management console















